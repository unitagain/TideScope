# DeepSeek LLM é›†æˆæŒ‡å—

## ä¸ºä»€ä¹ˆé€‰æ‹© DeepSeekï¼Ÿ

### å¯¹æ¯” OpenAI

| ç‰¹æ€§ | OpenAI (gpt-4o-mini) | DeepSeek (deepseek-chat) |
|------|---------------------|-------------------------|
| **é€Ÿç‡é™åˆ¶** | 3 RPM (å…è´¹å±‚) | 60 RPM (å…è´¹å±‚) |
| **ä»·æ ¼** | $0.15/1M tokens | $0.14/1M tokens |
| **è´¨é‡** | ä¼˜ç§€ | ä¼˜ç§€ (æ¥è¿‘ GPT-4) |
| **å»¶è¿Ÿ** | ä¸­ç­‰ | ä½ |
| **ä¸­æ–‡æ”¯æŒ** | è‰¯å¥½ | ä¼˜ç§€ |

**å¯¹äºæœ¬é¡¹ç›®**ï¼š
- åˆ†æ 46 ä¸ª open issues
- OpenAI: éœ€è¦ 15+ åˆ†é’Ÿï¼ˆé€Ÿç‡é™åˆ¶ï¼‰
- **DeepSeek: åªéœ€ 2-3 åˆ†é’Ÿ** âœ…

---

## å¿«é€Ÿå¼€å§‹

### 1. è·å– DeepSeek API Key

è®¿é—® [DeepSeek å¹³å°](https://platform.deepseek.com/)ï¼š
1. æ³¨å†Œè´¦å·
2. è¿›å…¥ API Keys é¡µé¢
3. åˆ›å»ºæ–°çš„ API Key
4. å¤åˆ¶å¯†é’¥

### 2. è®¾ç½®ç¯å¢ƒå˜é‡

**Windows PowerShell:**
```powershell
$env:DEEPSEEK_API_KEY="your-deepseek-api-key-here"
```

**Linux/Mac:**
```bash
export DEEPSEEK_API_KEY="your-deepseek-api-key-here"
```

**æ°¸ä¹…è®¾ç½® (æ¨è)**ï¼š
- Windows: ç³»ç»Ÿå±æ€§ â†’ ç¯å¢ƒå˜é‡
- Linux/Mac: æ·»åŠ åˆ° `~/.bashrc` æˆ– `~/.zshrc`

### 3. è¿è¡Œåˆ†æ

```bash
# ä½¿ç”¨ DeepSeek (æ¨è)
python -m cli.main analyze \
  --raw surfsense-raw.json \
  --output surfsense-report.json \
  --use-llm \
  --llm-provider deepseek

# æˆ–ä½¿ç”¨ OpenAI (å¦‚æœä½ æœ‰æ›´é«˜çš„é€Ÿç‡é™åˆ¶)
python -m cli.main analyze \
  --raw surfsense-raw.json \
  --output surfsense-report.json \
  --use-llm \
  --llm-provider openai
```

---

## å®Œæ•´å·¥ä½œæµç¨‹

### Step 1: æ‰«æé¡¹ç›®

```bash
cd F:\Github-TideScope\TideScope-main

python -m cli.main scan \
  --config config/surfsense.quick.yaml \
  --output surfsense-raw.json \
  --mode quick
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
âœ“ Scan completed
  - 155 Issues
  - 308 Pull Requests
```

### Step 2: ä½¿ç”¨ DeepSeek åˆ†æ

```bash
# è®¾ç½® API Key
$env:DEEPSEEK_API_KEY="sk-xxx"

# è¿è¡Œåˆ†æ
python -m cli.main analyze \
  --raw surfsense-raw.json \
  --output surfsense-report.json \
  --use-llm \
  --llm-provider deepseek
```

**å®æ—¶è¿›åº¦æ˜¾ç¤º**ï¼š
```
INFO Processing 0 code TODOs...
INFO Processing 46 open issues with LLM (skipping 109 closed)...
INFO [1/46] Analyzing issue #288: [FEATURE] Add a metabase connector...
INFO [2/46] Analyzing issue #474: [BUG] Cannot Register or Log In...
...
INFO [46/46] Analyzing issue #41: Encrypt stored API tokens...
INFO Completed processing 46 issues
INFO Processing 308 pull requests...
âœ“ Analysis completed
```

### Step 3: å¯åŠ¨å¯è§†åŒ–

```bash
# å¯åŠ¨åç«¯
cd F:\Github-TideScope\TideScope-main
uvicorn api.main:app --reload

# å¦å¼€ç»ˆç«¯å¯åŠ¨å‰ç«¯
cd F:\Github-TideScope\TideScope-main\web
npm run dev
```

è®¿é—® http://localhost:4173 æŸ¥çœ‹ StarMapï¼

---

## ä¼˜åŒ–ç­–ç•¥

### æ™ºèƒ½åˆ†æèŒƒå›´

ç³»ç»Ÿ**è‡ªåŠ¨ä¼˜åŒ–**ä»¥èŠ‚çœæˆæœ¬å’Œæ—¶é—´ï¼š

1. âœ… **åªåˆ†æå¼€æ”¾çš„ Issues**
   - å…³é—­çš„ issues ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼ˆç§’çº§ï¼‰
   - å¼€æ”¾çš„ issues ä½¿ç”¨ LLM åˆ†æï¼ˆæ›´å‡†ç¡®ï¼‰

2. âœ… **è·³è¿‡ Pull Requests**
   - PR é€šå¸¸ä¸éœ€è¦å¤æ‚åˆ†ç±»
   - ä½¿ç”¨ç®€å•è§„åˆ™æ¨æ–­å³å¯

3. âœ… **å¹¶å‘æ§åˆ¶**
   - 2 ä¸ªå¹¶å‘è¯·æ±‚é¿å…é€Ÿç‡é™åˆ¶
   - è‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚

### é¢„æœŸæ•ˆæœ

**46 ä¸ªå¼€æ”¾ issues**ï¼š
```
â”œâ”€ LLM æˆåŠŸ: ~40-45 ä¸ª (87-98%)
â”œâ”€ LLM å¤±è´¥: ~1-6 ä¸ª (å›é€€åˆ°å…³é”®è¯åŒ¹é…)
â””â”€ æ€»è€—æ—¶: 2-3 åˆ†é’Ÿ
```

**æˆæœ¬ä¼°ç®—**ï¼š
```
46 issues Ã— å¹³å‡ 300 tokens = 13,800 tokens
13,800 tokens Ã· 1,000,000 Ã— $0.14 = $0.002 (çº¦ 0.2 åˆ†é’±)
```

---

## éªŒè¯ç»“æœ

è¿è¡ŒéªŒè¯è„šæœ¬ï¼š

```bash
python check_llm.py
```

**é¢„æœŸè¾“å‡º**ï¼ˆDeepSeek æˆåŠŸï¼‰ï¼š
```
=== LLM Analysis Stats ===
With skills (LLM success): 40-45
Without skills (LLM failed/skipped): 1-6
Success rate: 87-98%

=== LLM Success Examples ===
1. [BUG] Cannot Register or Log In...
   Category: maintainability | Difficulty: intermediate
   Skills: ['Docker', 'Web Development', 'Database Management']
   Risk: 3 | Priority: 1.25

=== Category Distribution ===
  feature: 30-35
  maintainability: 8-12
  security: 3-5
  performance: 2-4
  unknown: 1-5  â† æ˜¾è‘—å‡å°‘ï¼
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: `DEEPSEEK_API_KEY not found`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```powershell
# ç¡®è®¤ç¯å¢ƒå˜é‡è®¾ç½®
echo $env:DEEPSEEK_API_KEY

# å¦‚æœä¸ºç©ºï¼Œé‡æ–°è®¾ç½®
$env:DEEPSEEK_API_KEY="sk-xxx"
```

### é—®é¢˜ 2: é€Ÿç‡é™åˆ¶ï¼ˆ429 é”™è¯¯ï¼‰

DeepSeek å…è´¹å±‚ï¼š60 RPM
- å½“å‰å¹¶å‘ï¼š2
- ç†è®ºæœ€å¤§ï¼š120 æ¬¡/åˆ†é’Ÿï¼ˆè¶³å¤Ÿï¼‰

å¦‚æœä»ç„¶é‡åˆ°ï¼š
1. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºåœ¨è°ƒç”¨ DeepSeek API
2. ç­‰å¾… 1 åˆ†é’Ÿåé‡è¯•

### é—®é¢˜ 3: è¿æ¥è¶…æ—¶

```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl https://api.deepseek.com

# å¦‚æœå¤±è´¥ï¼Œå¯èƒ½éœ€è¦ä»£ç†
```

---

## é«˜çº§é…ç½®

### ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹

```bash
python -m cli.main analyze \
  --raw surfsense-raw.json \
  --output surfsense-report.json \
  --use-llm \
  --llm-provider deepseek \
  --llm-model deepseek-coder  # ä¸“é—¨ä¼˜åŒ–ä»£ç ç†è§£
```

### æ‰¹é‡åˆ†æå¤šä¸ªé¡¹ç›®

```bash
# åˆ›å»ºæ‰¹å¤„ç†è„šæœ¬
for project in project1 project2 project3; do
  python -m cli.main analyze \
    --raw ${project}-raw.json \
    --output ${project}-report.json \
    --use-llm \
    --llm-provider deepseek
done
```

---

## æœ€ä½³å®è·µ

1. **é¦–æ¬¡åˆ†æä½¿ç”¨ DeepSeek**
   - å»ºç«‹å‡†ç¡®çš„åŸºçº¿æ•°æ®
   - æˆæœ¬ä½ä¸”é€Ÿåº¦å¿«

2. **å®šæœŸæ›´æ–°åˆ†æ**
   - æ¯å‘¨/æ¯æœˆé‡æ–°æ‰«æ
   - åªåˆ†ææ–°å¢çš„å¼€æ”¾ issues

3. **å…³é”®é¡¹ç›®ä½¿ç”¨ LLM**
   - å®‰å…¨æ€§é¡¹ç›®
   - é«˜ä¼˜å…ˆçº§ bugs
   - å¤æ‚çš„æŠ€æœ¯å€ºåŠ¡

4. **ç»„åˆä½¿ç”¨**
   - æ—¥å¸¸ï¼šå…³é”®è¯åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰
   - é‡è¦å†³ç­–ï¼šDeepSeek åˆ†æï¼ˆå‡†ç¡®ï¼‰

---

## æŠ€æœ¯ç»†èŠ‚

### API å…¼å®¹æ€§

DeepSeek ä½¿ç”¨ OpenAI SDKï¼Œå®Œå…¨å…¼å®¹ï¼š

```python
from openai import OpenAI

client = OpenAI(
    api_key=os.environ.get('DEEPSEEK_API_KEY'),
    base_url="https://api.deepseek.com"
)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[...],
    response_format={"type": "json_schema", "json_schema": schema}
)
```

### å¹¶å‘å¤„ç†

```python
# ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
max_workers = 2  # é¿å…é€Ÿç‡é™åˆ¶
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = [executor.submit(analyze_issue, issue) for issue in issues]
    for future in as_completed(futures):
        result = future.result(timeout=30)
```

---

## æ€»ç»“

âœ… **æ¨èé…ç½®**ï¼š
- Provider: **DeepSeek**
- Model: `deepseek-chat`ï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰
- æˆæœ¬: ~$0.002 per 50 issues
- é€Ÿåº¦: 2-3 åˆ†é’Ÿ per 50 issues

ğŸš€ **ç«‹å³å¼€å§‹**ï¼š
```bash
$env:DEEPSEEK_API_KEY="your-key"
python -m cli.main analyze --raw surfsense-raw.json --output surfsense-report.json --use-llm --llm-provider deepseek
```
